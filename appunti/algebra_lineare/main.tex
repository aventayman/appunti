\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{Algebra Lineare e Geometria Analitica}\\Ingegneria dell'Automazione Industriale}
\author{\huge{Ayman Marpicati}}
\date{A.A. 2022/2023}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents

\chapter{Nozioni preliminari}
\section{Relazioni su un insieme}
\dfn{Relazione su un insieme}{Una \textbf{relazione} su un insieme \textit{A} è un qualunque sottoinsieme di \(\mcR\) del prodotto cartesiano \(A \times A\).

Una relazione \(\mcR\) su un insieme \textit{A} si dice:
\begin{itemize}
    \item \textbf{riflessiva} se, per ogni \(a \in A, \ a\mcR a\);
    \item \textbf{simmetrica} se, per ogni \(a,b \in A, \ a\mcR b \ \text{allora} \ a = b\);
    \item \textbf{antisimmetrica} se, per ogni \(a,b \in A, \ a\mcR b \text{ e } b\mcR a \text{ allora } a = b\);
    \item \textbf{transitiva} se, per ogni \(a,b,c \in A, \ a\mcR b \text{ e } b\mcR c \text{ allora } a \mcR c\);
\end{itemize}}

\dfn{Relazione d'ordine totale}{Una relazione d'ordine \(\mcR\) su un insieme \textit{A} si dice \textbf{relazione d'ordine} se è riflessiva, antisimmetrica e transitiva. Se inoltre, gli elementi di \textit{A} sono a due a due confrontabili, cioè, per ogni \(a, b \in A\), risulta \(a \mcR b\) oppure  \(b \mcR a\), la relazione \(\mcR\) si dice \textbf{relazione d'ordine totale}.}

\section{Strutture algebriche}
\dfn{Gruppo}{Sia \((G, \star)\) un insieme con un'operazione \(\star\). La struttura \((G, \star)\) si dice \textbf{gruppo} se:
\begin{itemize}
    \item l'operazione \(\star\)  è associativa;
    \item esiste in \textit{G} l'elemento neutro;
    \item ogni elemento di \(g \in G\) è simmetrizzabile.  
\end{itemize}
Se l'operazione \(\star\) soddisfa anche la proprietà commutativa, il gruppo si dice \textbf{abeliano}.}

\dfn{Campo}{Sia \textit{A} un insieme sul quale sono definite due operazioni che indichiamo con i simboli "\(+\)" e "\(\cdot\)" e che chiamiamo somma e prodotto rispettivamente. La struttura \((A, +, \cdot)\) è un \textbf{campo} se sussistono le condizioni seguenti:
\begin{itemize}
    \item \((A, +)\) è un gruppo abeliano il cui elemento neutro è indicato con 0;
    \item \((A\backslash\{0\}, \cdot)\) è un gruppo abeliano con elemento neutro \(e \neq 0\);
    \item valgono le proprietà distributive (sinistra e destra) del prodotto rispetto alla somma, cioè per ogni \(a,b,c \in A\) \[
        a \cdot (b + c) = a \cdot b + a \cdot c; \ (a + b) \cdot c = a \cdot c + b \cdot c
    \]
\end{itemize}}

\section{Matrici}

\dfn{Matrice}{Dato un campo K si dice \textbf{matrice} di tipo \(m \times n\) su \(K\) una tabella del tipo: \[ A=
\begin{pmatrix}
    a _{11} & a _{12} & \hdots & a _{1n} \\
    a _{21} & a _{22} & \hdots & a _{2n} \\
    \vdots & \vdots & \ddots & \vdots \\
    a _{m1} & a _{m2} & \hdots & a _{mn} \\
\end{pmatrix}
\] avente \(m\) righe ed \(n\) colonne, i cui elementi \(a _{ij}\) sono elementi di \(K.\) }

\dfn{Matrice quadrata}{Una matrice di tipo \(n \times n\) è detta \textbf{matrice quadrata} di ordine \(n\). Queste vengono indicate con \(M_n(K)\).}

\dfn{Prodotto righe per colonne}{Date le matrici \(A = (a _{ih}) \in K ^{m,n}(K)\) con \(i \in I_m, h \in I_n\) e \(B = (b _{hj}) \in K ^{n,p}\) con \(h \in I_n, j \in I_p\), si dice \textbf{prodotto righe per colonne} di \(A\) per \(B\) la matrice \[
    A \cdot B = (c _{ij}) \text{ con } i \in I_m, \ j \in I_p \qquad \text{ove}
\] \[
    c _{ij} = a _{i1} b _{1j} + a _{i2} b _{2j} + ... + a _{in} b _{nj}= \sum_{h \in I_n} a _{ih} b _{hj}
\]    }

\ex{}{Prendiamo per esempio le due matrici: \[A=
\begin{pmatrix}
    -3 & 0 & 2 \\
    -4 & 7 & 1 \\
\end{pmatrix} \quad B=
\begin{pmatrix}
    -5 & -1 & 2 \\
    0 & 1 & -2 \\
    1 & 1 & 3 \\
\end{pmatrix}\]
 Il loro prodotto è \[
\begin{pmatrix}
    -3 \cdot (-5) + 0 \cdot 0 + 2 \cdot 1 & -3 \cdot (-1) + 0 \cdot 1 + 2 \cdot 1 & -3 \cdot 2 + 0 \cdot (-2) + 2 \cdot 3 \\
    -4 \cdot (-5) + 7 \cdot 0 + 1 \cdot 1 & -4 \cdot (-1) + 7 \cdot 1 + 1 \cdot 1 & -4 \cdot 2 + 7 \cdot (-2) + 1 \cdot 3 \\
\end{pmatrix}
\] Quindi \[
    A \cdot B =
\begin{pmatrix}
    17 & 5 & 0 \\
    21 & 12 & -19 \\
\end{pmatrix}
\]}
\dfn{Matrice identica}{L'elemento neutro delle matrici quadrate di ordine \(n\) è la \textbf{matrice identica}, cioè la matrice: \[
\begin{pmatrix}
    1 & 0 & \hdots & 0 \\
    0 & 1 & \hdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \hdots & 1 \\
\end{pmatrix}
\]}

\dfn{Trasposta di una matrice}{Sia \(A = (a _{ij})\) una matrice di \(K ^{m,n}\). Si dice \textbf{trasposta} di \(A\) la matrice \(K^{n,m}\) ottenuta scambiando tra loro le righe con le colonne, cioè \(^{t}A = (b _{ji})\) ove \(b _{ji} = a _{ij}\) per ogni \(i \in I_n\) e \(j \in I_m.\)  }



\chapter{Spazi vettoriali}
\section{Generalità}
\dfn{Spazio vettoriale}{Siano \(K\)  un campo e \(V\) un insieme. Si dice che \(V\) è uno \textbf{spazio vettoriale} sul campo \(K\), se sono definite due operazioni: un'operazione interna binaria su \(V\), detta somma, \(+: V \times V \rightarrow V\) e un'operazione estrema detta prodotto esterno o prodotto per scalari, \(\cdot:K \times V \rightarrow V\), tali che
\begin{itemize}
    \item \((V, +)\) sia un gruppo abeliano;
    \item il prodotto esterno \(\cdot\) soddisfi le seguenti proprietà:
        \begin{itemize}
            \item \( (h \cdot k) \cdot v = h \cdot (k \cdot v) \quad \forall h, k \in K \quad e \quad \forall v \in V \) 
            \item \( (h + k) \cdot v = h \cdot v + k \cdot v \quad \forall h, k \in K \quad e \quad \forall v \in V\)
            \item \(h \cdot (v + w) = h \cdot v + h \cdot w \quad \forall h,k \in K \quad e \quad \forall v, w \in V\)
            \item \(1 \cdot v = v \quad \forall v \in V\)
        \end{itemize}
\end{itemize}}
Gli elementi dell'insieme \textit{V} sono detti \textbf{vettori}, gli elementi del campo \textit{K} sono chiamati \textbf{scalari}. L'elemento neutro di \((V, +)\) è detto \textbf{vettor nullo} e indicato \ul{0} per distinguerlo da 0, zero del campo \textit{K}. L'opposto di ogni vettore \textbf{v} viene indicato con \textbf{-v}.

\thm{}{Sia \textit{V} uno spazio vettoriale sul campo \textit{K}, siano \(k \in K\)  e \(v \in V\). Allora \[
    kv = \ul{0} \iff k = 0 \text{ oppure } v = \ul{0}
\]}
\pf{Dimostrazione}{Se k = 0 \[
    0v = (0+0)v = 0v + 0v
\] e sommando \(-0v\) ad ambo i membri si ottiene appunto \(\ul{0} = 0v\). Se è \(v = \ul{0}\), si procede nel modo analogo. Viceversa, se \(kv = \ul{0}\)  e \(k \neq 0\) dimostriamo che \(v = \ul{0}\). Dato che \(k \neq 0\), esiste l'inverso \(k ^{-1} \in K\) e, moltiplicando ambo i membri della precedente uguaglianza per \(k ^{-1}\) si ottiene \(k ^{-1}(kv) = k ^{-1} \ul{0}\) che, per quanto dimostrato in precedenza dà il \(\ul{0}\). Dato che \(k^{-1}(kv) = (k^{-1}k)v = 1v = v\), per la proprietà 4, si ha \(v = \ul{0}\).  }

\section{Sottospazi di uno spazio vettoriale}
\dfn{Sottospazio vettoriale}{Sia \(\emptyset \neq U \subseteq V\), diremo che \(U\) è \textbf{sottospazio vettoriale} di \(V\) se è esso stesso uno spazio vettoriale rispetto alla restrizione delle stesse operazioni.}

\mprop{Primo criterio di riconoscimento}{Sia \(V(K)\) uno spazio vettoriale e sia \(\emptyset \neq  U \subseteq V\) un suo sottoinsieme. Il sottoinsieme \(U\) è uno spazio vettoriale di \(V\) se, e soltanto se, sono verificate le seguenti condizioni:
\begin{enumerate}
    \item \(\forall u, u' \in U \quad u + u' \in U\) 
    \item \(\forall k \in K, \ \forall u \in U \quad ku \in U\) 
\end{enumerate}}

\mprop{Secondo criterio di riconoscimento}{Sia \(V(K)\) uno spazio vettoriale sul campo \(K\) e sia \(\emptyset \neq U \subseteq V\), \(U\) è sottospazio di \(V(K)\) se e soltanto se 
   \[
       hv_{1} + kv_{2} \in U \quad \forall v_{1}, v_{2} \in U \quad e \quad h, k \in K
   \] 
}

\section{Indipendenza e dipendenza lineare}
\dfn{Combinazione lineare}{Siano \(v _{1}, v_2, ..., v_n \in V(K)\) si dice combinazione lineare di vettori \(v_1, v_2, ..., v_n\) ogni vettore \(v\): \[
    v = k_1 \cdot v_1 + k_2 \cdot v_2 + ... + k_n \cdot v_n \quad \text{con} \ k_1, k_2, ..., k_n \in K
\] }
\dfn{Sistema di vettori libero}{Sia \(V(K)\) e sia \(A\) un sistema di vettori di \(V(K)\), \(A=[v_1, v_2, ..., v_n]\), allora \(A\) si dice \textbf{libero} se l'unica combinazione lineare di vettori di \(A\) che dà il vettore nullo è a coefficienti tutti nulli \[
    \ul{0} = k_1 \cdot v_1 + k_2 \cdot v_2 + ... + k_n \cdot v_n \implies k_1 = k_2 = ... = k_n = \ul{0}
\]
Se \(A\) è libero i suoi vettori si dicono \textbf{linearmente indipendenti}.}


\dfn{Sistema di vettori legato}{Sia \(V(K)\) e sia \(A\) un sistema di vettori di \(V(K)\), \(A=[v_1, v_2, ..., v_n]\), allora \(A\) si dice \textbf{legato} se \textbf{non} è libero. Quindi:\[
        \exists k_1, k_2, ..., k_n \ \text{non tutti nulli} : \ \ul{0}=k_1 \cdot v_1 + k_2 \cdot v_2 + ... + k_n \cdot v_n
\]
Se \(A\) è legato i suoi vettori si dicono \textbf{linearmente dipendenti}.}
Qui di seguito daremo delle proposizioni riguardo ai sistemi liberi e legati:
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\). Se \(\ul{0}\) appartiene ad \(A\), il sistema \(A\) è legato.}
\pf{Dimostrazione}{Sia \(\ul{0} \in A\), senza perdita di generalità, possiamo supporre che \(\ul{0} = v_1\) quindi: \[
    1 \cdot v_1 + 0 \cdot v_2 + ... + 0 \cdot v_n = 1 \cdot \ul{0} + \ul{0} = \ul{0} \implies \ \text{A è legato}
\]}
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\). Se in \(A\) appaiono due vettori proporzionali allora A è legato.}
\pf{Dimostrazione}{Senza perdita di generalità possiamo supporre che \(v_1 = k v_2\) e quindi: \[
    1v_1 + k v_2 + 0v_3 + ... + 0 v_n = v_1 - kv_2 + \ul{0} = \ul{0} \implies \ \text{A è legato}
\]}
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\). A è legato se e solo se almeno uno dei vettori si può riscrivere come combinazione lineare degli altri.}
\pf{Dimostrazione}{\( \implies \): Per ipotesi \(A\) è legato e quindi: \[
    \ul{0}=k_1v_1 + k_2 v_2 + ... + k_n v_n \ \text{con almeno un } k_i = 0
\] Senza perdita di generalità supponiamo che \(k_1 \neq 0\)
    \begin{gather*} 
    -k_1 v_1 = k_2 v_2 + ... + k_n v_n \qquad v_1 = \frac{1}{k_1} (-k_2 v_2 - ... -k_n v_n) \\
   v_1 = -\frac{k_2}{k_1}v_2 - \frac{k_3}{k_1}v_3 - ... - \frac{k_n}{k1}v_n
\end{gather*}
e quindi \(v_1\) è combinazione lineare di \(v_1, ..., v_n\).\\
\( \impliedby \): Per ipotesi uno dei vettori di \(A\) è combinazione lineare degli altri e senza perdita di generalità: \[
    v_1 = k_2 v_2 + k_3 v_3 + ... + k_n v_n \qquad \ul{0}= -1v_1 + k_2 v_2 + ... + k_n v_n
\] siccome \(-1 \neq 0\) \(A\) è legato. }
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\) e sia \(u \in V(K)\). Se \(A \cup \{u\}\) è legato, allora \(u\) è combinazione lineare dei vettori di \(A\).}
\pf{Dimostrazione}{Per ipotesi \(A \cup \{u\}\) è legato, cioè: \[
    \exists k_1, k_2, ..., k_n, b \in K \ \text{ non tutti nulli } : \ \ul{0} = k_1v_1 + k_2v_2 +...+k_nv_n + bu
\] sia per assurdo \(b = 0\) \[
    \ul{0}=k_1v_1 + k_2v_2 + ... + k_nv_n \text{ con } k_1 \neq 0 \ \implies \ A \text{ è legato, \textbf{assurdo!} } \implies \ b \neq 0
\] \[
    -bu = k_1v_1 + k_2v_2 + ... + k_nv_n \quad u = -\frac{k_1}{b}v_1 - \frac{k_2}{b}v_2 - ... - \frac{k_n}{b}v_n
\] \( \implies \) \(u\) è combinazione lineare dei vettori \(v_1, v_2, ..., v_n\)  }
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\) e sia \(B \supseteq A\) sistema di vettori di \(V(K)\). Se \(A\) è legato allora anche \(B\) è legato.}
\pf{Dimostrazione}{\[
    \exists k_1, k_2, ..., k_n \in K \ \text{ non tutti nulli } : \ \ul{0} = k_1v_1 + k_2v_2 +...+k_nv_n
\] Se \(B=[v_1, v_2, ..., v_n, w_1, w_2, ..., w_m]\) allora \[
    \ul{0} = k_1v_1 + k_2v_2 +...+k_nv_n + 0w_1 + 0w_2 + ... + 0w_m
\]\( \implies \ B\) è legato.}
\mprop{}{Sia \(A=[v_1, v_2, ..., v_n]\) un sistema di generatori di \(V(K)\) e sia \(B \subseteq A\) sistema di vettori di \(V(K)\), se \(A\) è libero, allora \(B\) è libero.}
\pf{Dimostrazione}{Sia, per assurdo, \(B\) legato, allora per la proposizione precedente anche \(A\) è legato. \textbf{Assurdo!} Quindi \(B\)  è libero.} 

\section{Sistemi di generatori di uno spazio vettoriale}
\dfn{Sistema di generatori}{Sia \(A\) sistema di vettori di \(V(K)\). \(A\) si dice sistema di generatori di \(V(K)\) se ogni \(v \in V(K)\) si può scrivener come combinazione lineare di un numero finito di vettori di A.}

\dfn{Copertura lineare}{Sia \(A\) un sistema di vettori di \(V(K)\) si dice copertura (o chiusura) lineare di \(A\) l'insieme \(\mcL(A)\) di tutte le combinazioni lineari di sottoinsiemi finiti di A.}
\nt{Dato \(A\) sistema di vettori di \(V(K)\) \begin{enumerate}
    \item \(\mcL(A)\) è il più piccolo sottospazio di \(V(K)\) che contiene \(A\) 
    \item \(\mcL(A) \le V(K)\) 
    \item \(\mcL(\mcL(A)) = \mcL(A)\)
\end{enumerate}}
Ogni spazio vettoriale ammette un sistema di generatori e:
\begin{itemize}
    \item se \(V(K)\) ammette un sistema di generatori finito \( \implies\) \(V(K)\) si dice finitamente generato.
    \item se ogni sistema di generatori di \(V(K)\) ha cardinalità infinita \( \implies\) \(V(K)\) non è finitamente generato.
\end{itemize}

\section{Basi e dimensione}
\mlenma{}{Sia \(S=[v_1, v_2, ..., v_n]\) un sistema di generatori per uno spazio vettoriale \(V(K)\), e sia \(v \in S\) combinazione lineare degli altri vettori (linearmente dipendente dagli altri) \( \implies\) \(S\backslash \{v\} \) è sistema di generatori per \(V(K)\)}
\pf{Dimostrazione}{Sia, senza perdere di generalità, \(v_1\) combinazione lineare di \(v_2, v_3, ..., v_n\) \[
    v_1 = k_2v_2 + k_3v_3 + ... + k_nv_n
\] sia \(v \in V(K)\) \[
    v = h_1v_1 + h_2 v_2 + ... + h_nv_n = h_1(k_2v_2 + ... + k_nv_n) + h_2v_2 + ... + h_nv_n
\] \[
v = \underbrace{(h_1k_2 + h_2)}_{\in K}v_2 + ... + \underbrace{(h_1k_n + h_n)}_{\in K}v_n \ \in \mcL([v_2, v_3, ..., v_n]) = \mcL(S \backslash \{v_1\} )
\] \( \implies \ S \backslash \{v_1\} \) è un sistema di generatori.}

\thm{}{Sia \(V(K)\) uno spazio vettoriale finitamente generato, non banale (\(V(K) \neq \{\ul{0}\} \)), allora esso ammette un sistema libero di generatori.}
\pf{Dimostrazione}{sia \(A = [v_1, v_2, ..., v_n]\) un sistema di generatori per \(V(K)\), abbiamo due possibilità: \begin{enumerate}
    \item A è libero \( \implies \) A è un sistema di generatori libero;
    \item A è legato \( \implies \ \exists v \in A\) combinazione lineare degli altri, senza perdita di generalità possiamo porre \(v = v_1 \ \implies \ A\backslash \{v_1\} = A_1 \) è sistema di generatori.
\end{enumerate} 
Se ci troviamo nel secondo caso possiamo reiterare il procedimento e trovare \(A_2 \rightarrow A_3 \rightarrow ...\) finché non arriviamo ad un sistema libero di generatori.

Osserviamo che \(A\) contiene almeno un \(v \in A: \ v \neq \ul{0}\), questo perché \(A_n = [0]\) e \(v_n \neq \ul{0}\) perché \(A \neq \{\ul{0} \} \ \implies \ A_n\) è necessariamente libero.  }

\dfn{Base}{Sia \(S = (v_1, v_2, ..., v_n)\) sequenza libera di vettori di \(V(K)\). \(S\) è detta base se e solo se \(S\) è una sequenza libera di generatori.}

\dfn{Base canonica di \(\RR^{n} \) }{\(((1,0,0,...,0)(0,1,0,...,0),...,(0,0,0,...,1))\) è una base canonica per \(\RR^{n} \).}

\mlenma{Lemma di Steinitz}{Sia \(V(K)\) uno spazio vettoriale finitamente generato. Sia \(B = [v_1, v_2, ..., v_n]\) sistema di generatori e \(A = [u_1, u_2, ..., u_m]\) sistema libero. Allora la cardinalità di A sarà sempre minore o uguale a quella del sistema di generatori. \((m \le n)\)  }

\pf{Dimostrazione}{Sia per assurdo \(m >n\), poiché \(B\) genera \(V(K)\) \(u_1\) si scrive come: \[
    u_1 = k_1v_1 + k_2 v_2 + ... + k_n v_n
\] Essendo \(A\) libero \(u_1 \neq \ul{0} \implies k_1, k_2, ..., k_n\) non sono tutti nulli \( \implies\) senza perdita di generalità \(k_1 \neq 0\) \[
    -k_1v_1 = -u_1 + k_2v_2 + ... + k_nv_n \qquad v_1 = \frac{1}{k_1}(u_1 - k_2v_2 - ... - k_nv_n)
\] \[
\implies v_1 \in \mcL([u_1, v_2, v_3, ..., v_n])
\] B è sistema di generatori, \(B \cup \{u_1\} \) è sistema di generatori, di conseguenza \((B \cup \{u_1\} \backslash \{v_1\} ) = B_1 = [u_1, v_2, ..., v_n]\) è ancora sistema di generatori per \(V(K)\).

Allo stesso modo posso riscrivere \[
    u_2 = \alpha u_1 + h_2v_2 + h_3 v_3 + ... + h_n v_n \quad \text{con} \ \alpha, h_2, h_3, ..., h_n \in K
\] Se avessimo \(h_2 = h_3 = ... = h_n = 0 \ u_2 = \alpha\) ma ciò non può succedere perché \(A\) è libero \( \implies \exists h_i \neq 0\) e senza perdita di generalità supporremo \(h_2 \neq 0\) quindi: \[
    -h_2 v_2 = \alpha u_1 - u_2 + h_3 v_3 + ... + h_n v_n \qquad v_2 = \frac{1}{h_2} (-\alpha u_1 + u_2 - h_3 v_3 - ... - h_n v_n)
\] \(v_2\) è linearmente dipendente da \(B_2 = [u_1, u_2, v_3, ..., v_n]\) e \(B_2\), per lo stesso motivo di \(B_1\) è ancora sistema di generatori.

Ora immaginiamoci di reiterare il procedimento \(n\) volte fino a trovare un sistema \(B_n = [u_1, u_2, ..., u_n]\). Siccome avevamo supposto che \(m > n\) essendo \(B_n\) sistema di generatori dovremo essere in grado di scrivere anche \(u _{n+1}\) come combinazione lineare dei vettori di \(B_n\), cioè: \[
    u _{n+1} \in \mcL(B_n) \qquad u _{n+1} = \alpha_1 u_1 + \alpha_2 u_2 + ... + \alpha_n u_n
\] questo comporta che \(A\) sia legato, ma questo è \textbf{assurdo!} \( \implies \ m \le n\).}

\thm{}{Sia \(V(K)\) uno spazio vettoriale finitamente generato, e siano \(B_1\) e \(B_2\) due sue basi le loro cardinalità sono uguali: \[
    B_1 = (v_1, v_2, ..., v_n) \qquad B_2 = (u_1, u_2, ..., u_n) \qquad m=n
\]} 
\pf{Dimostrazione}{Per dimostrarlo è sufficiente applicare il lemma di Steinitz \begin{itemize}
    \item \(B_1\) sistema di generatori, \(B_2\) sistema libero \( \implies \ n \ge m\); 
    \item \(B_2\) sistema di generatori, \(B_1\) sistema libero \( \implies \ m \ge n\). 
\end{itemize} \(m \ge n \text{ e } n \ge m \iff n = m\). }

\dfn{Dimensione}{Dato uno spazio vettoriale finitamente generato, non banale, chiamiamo \textbf{dimensione} di \(V\) la cardinalità di una qualsiasi delle sue basi. Inoltre se \(V = \{0\} \) poniamo la \(\dim(V)=0\) }

Qui di seguito enunciamo una serie di conseguenze del lemma di Steinitz.
\mprop{}{Sia \(V_n(K)\) uno spazio vettoriale di dimensione \(n\) su \(K\) e sia \(S=[v_1, v_2, ..., v_n]\) un sistema di generatori. Allora \(S\) è libero.}
\pf{Dimostrazione}{Sia \(B=[w_1, w_2, ..., w_n]\) una base di \(V_n(K)\). Sia per assurdo \(S\) legato.
Senza perdita di generalità \(v_1 = k_2v_2 + k_3v_3 + ... + k_nv_n\). Allora \(S' = S \backslash \{v_1\} \) è ancora sistema di generatori. \(|S'| = n-1 \ge |B|\) perché \(B\) è libero per il lemma di Steinitz. \textbf{Assurdo!}. Quindi \(S\) è libero.}

\mprop{}{Sia \(V(K)\) uno spazio vettoriale di dimensione \(n\) sul campo \(K\). Sia \(S=[v_1, v_2, ..., v_n]\) un sistema libero. Allora \(S\) è anche un sistema di generatori.}
\pf{Dimostrazione}{Sia \(B=[w_1, w_2, ..., w_n]\) una base di \(V(K)\), supponiamo per assurdo che \(S\) non generi. \[
    \implies \ \exists v \in V \text{ con } v \neq \ul{0} 
\] \(S' = S \cup \{u\} \) è ancora libero, supponiamo per assurdo che non lo sia: \[
    \text{ sia } \ul{0} = k_1v_1 + k_2v_2 + ... + k_nv_n + \alpha v \text{ con } \alpha \neq 0
\] \[
    \text{ altrimenti avremmo: } \ul{0} = k_1v_1 + k_2v_2 + ... + k_nv_n
\] \[
    v = \frac{1}{\alpha}(-k_1v_1 - k_2 v_2 - ... - k_nv_n) \in \mcL(S)
\] \( \implies v \in \mcL(S)\) \textbf{assurdo!} Contro l'ipotesi che \(v \notin \mcL(S) \ \implies \ S'\) è libero. \[
\underbrace{|S'| = n+1}_{\text{sistema libero}} \le \underbrace{|B| = n}_{\text{sequenza di generatori}} \rightarrow \text{ per il lemma di Steinitz }
\] \textbf{Assurdo!} \( \implies\) \(S\) è un sistema di generatori.}

\mprop{}{\(m\) vettori in \(V_n(K)\) con \(m > n\) sono sempre linearmente dipendenti.}
\pf{Dimostrazione}{Siano per assurdo [\(v_1, v_2, ..., v_m\)], \(m\) vettori linearmente indipendenti con \(m > n\). Sia \(B\) una base di \(V_n(K)\). \(m = |S=[v_1, v_2, ..., v_m]| \le |B| = n\) per il lemma di Steinitz. Ma per ipotesi \(m > n\), \textbf{assurdo!} }

\mprop{}{\(m\) vettori in \(V_n(K)\) con \(m < n \implies\) non possono generare. }
\pf{Dimostrazione}{siano \(v_1, v_2, ..., v_m\) per assurdo \(m\) vettori che generano \(V_n(K)\) con \(m < n\) allora: \[m = |S=[v_1, v_2, ..., v_n]| \ge |B|=n \ \text{ con } \ m \ge n \quad \text{per il lemma di Steinitz}\] \textbf{Assurdo!} Va contro all'ipotesi.}

\thm{Teorema di caratterizzazione delle basi}{Sia \(B=(v_1, v_2,...,v_n)\) una sequenza di vettori di \(V(K)\). \(B\) è una base se e solo se ogni vettore di \(V\) si può scrivere in maniera univoca come combinazione lineare dei vettori di \(B\). \[
    \forall v \in V,\ \exists ! \ v = k_1v_1 + k_2 v_2 + ... + k_n v_n \quad k_i \in K
\]}
\pf{Dimostrazione}{
\( \implies\) sia \(B\) una base di \(V\). Per ogni \(v\) si ha che \(v \in \mcL(B)\) perché \(B\) è una sequenza di generatori. Supponiamo per assurdo che esista \(v \in V\): \[
    v = v = k_1v_1 + k_2 v_2 + ... + k_n v_n = h_1 v_1 + h_2 v_2 + ... + h_n v_n \quad \text{ con almeno un  } k_i \neq h_i 
\] \[
(k_1 - h_1) v_1 + (k_2 - h_2) v_2 + ... + (k_n - h_n) v_n = \ul{0} 
\] \(B\) è una sequenza libera, quindi \((k_i - h_i) = 0 \implies k_i = h_i\) perché l'unica combinazione lineare che dà il vettore nullo è quella a coefficienti tutti nulli.
Ma avevamo supposto che \(k_i \neq h_i \implies\) \textbf{assurdo!} \( \implies \exists!\) la combinazione lineare dei vettori di \(B\) che dà \(v \ (\forall v \in V)\).

\( \impliedby\) per ipotesi \(\forall v \in V \ \exists !\) combinazione lineare dei vettori di \(B\) che dà \(v\). \(B\) è una sequenza di generatori, cioè \(\forall v \in V \implies v \in \mcL(B)\). Supponiamo per assurdo che \(B\) sia legato \(\implies \exists k_i \in K\) non nullo: \[
    \ul{0} = k_1v_1 + k_2 v_2 + ... + k_n v_n \quad \ul{0} = 0v_1 + 0v_2 + ... + 0v_n
\] quindi esistono almeno due combinazioni lineari di \(B\) che danno \(\ul{0} \). Dato che \(\ul{0} \in V\) per ipotesi esiste un unica combinazione lineare dei vettori di \(B\) che dà \(\ul{0} \). \textbf{Assurdo!} Quindi \(B\) è una sequenza libera e \(B\) è una base per \(V\).}

\dfn{Componenti di un vettore rispetto ad una base}{Sia \(B=(v_1, v_2, ..., v_n)\) una base di \(V_n(K)\) e sia \(v \in V\). Chiameremo componenti di \(v\) rispetto alla base \(B\) la sequenza \((k_1, k_2, ..., k_n)\): \[
    v = k_1v_1 + k_2 v_2 + ... + k_nv_n
\]}

\mprop{}{Sia \(V_n(K)\) uno spazio vettoriale di dimensione \(n\) sul campo \(K\), allora \(V_n(K)\) ammette almeno un sottospazio di dimensione \(m\) \(\forall 0 \le m \le n\). }
\pf{Dimostrazione}{sia  \(B=(v_1, v_2,...,v_n)\) una base di \(V_n(K)\) e sia \(0 \le m \le n\), ci sono due possibilità: \begin{enumerate}
    \item \(m=0 \implies\) \{\ul{0} \} è il sottospazio voluto;
    \item \(0 < m \le n\) e quindi \(S=(v_1, v_2,...,v_m)\)
\end{enumerate} \(\mcL(S)\) ha dimensione \(m\) perché \(S\) è libero \((S \subseteq B)\) e genera, per definizione \(\mcL(S)\).}

\newpage
\mprop{}{Siano \(U, W \le V_n(K)\) e sia \(U \le W\), allora: \begin{enumerate}
    \item \(\dim(U) \le \dim(W)\)
    \item \(U = W \iff \dim(U) = \dim(W)\)
\end{enumerate}}
\pf{Dimostrazione}{Dimostriamo i due punti:\begin{enumerate}
        \item Sia \(B\) base per \(U\) e \(B'\) base per \(W\), se per assurdo \[\underbrace{\dim(U) = |B|}_{\text{sequenza libera di \(W\) }} > \underbrace{\dim(W) = |B'|}_{\text{genera \(W\)} } \] contro il lemma di Steinitz. 
        \item \( \implies\) è banale; \\
        \( \impliedby\) sia per assurdo \(U < W\) e sia \(B\) base di \(U\), allora \[
            |B| = \dim(U) = \dim(W)
        \] quindi \(B\) è una base anche per \(W\) \( \implies \mcL(B) = W \implies W = U\) \textbf{Assurdo!}
\end{enumerate}}

\thm{Teorema del completamento ad una base}{Sia \(V_n(K)\) uno spazio vettoriale di dimensione \(n\) e sia \(A=(v_1, v_2,...,v_p)\), ove \(p \le n\), una sequenza libera di vettori in \(V_n(K)\). Allora, in una qualunque base di \(B\) di \(V_n(K)\), esiste una sequenza \(B'\) di vettori, tale che \(A \cup B'\) è una base di \(V_n(K)\).}

\section{Intersezione e somma di sottospazi}
\mprop{}{Sia \(V_n(K)\) uno spazio vettoriale di dimensione \(n\) sul campo \(K\) e siano \(U, V \le V \implies U\cap W\) è sottospazio di \(V\).}
\pf{Dimostrazione}{Richiamo il secondo criterio di riconoscimento dei sottospazi. \(U \cap W\) è un sottospazio di \(V\) \(\iff\) è sottoinsieme non vuoto di \(V\): \[
    \forall v_1, v_2 \in U \cap W, \ \forall k_1, k_2 \in K, \ k_1 v_1 + k_2v_2 \in U \cap W
\] \(U \cap W\) è sottoinsieme non vuoto di \(V\), perché \(U \subseteq V\), \(W \subseteq V\) e \(\ul{0} \in U \cap W\). Siano ora \(v_1, v_2 \in U \cap W\) e \(k_1, k_2 \in K\), osserviamo per il secondo criterio di riconoscimento che \(k_1 v_1 + k_2 v_2 \in U\) e per lo stesso motivo \(k_1 v_1 + k_2 v_2 \in W\) \( \implies k_1 v_1 + k_2 v_2 \in U \cap W \implies U \cap W\) è un sottospazio vettoriale.}

\nt{Sotto le stesse ipotesi della proposizione precedente abbiamo che \(U \cup W\) non è un sottospazio a meno che \(U \subseteq W\) oppure \(W \subseteq U\).}

\dfn{Spazio di somma}{Dati \(U\) e \(W \le V\) spazio vettoriale di dimensione \(n\) su \(K\) definiamo lo \textbf{spazio di somma} come: \[U + W := \{u + w \ | \ u \in U \ e \ w \in W\} \]}

\mprop{}{Dati \(U\) e \(W \le V\) spazio vettoriale di dimensione \(n\) su \(K\) abbiamo che: \(U + W \le V\) }
\pf{Dimostrazione}{Osserviamo che \(U + W \subseteq V\) perché dato \(u \in U \) e \(w \in W\), \(u \in V\) e \(w \in V \implies u + w \in V\), il quale non è vuoto perché \(\ul{0} \in U + W\). Siano \(v_1, v_2 \in U + W\) e siano \(k_1, k_2 \in K\) \[
    k_1 \cdot \underbrace{v_1}_{\text{\(=u_1 + w_1\) }}  + k_2 \cdot \underbrace{v_2}_{\text{\(= u_2 + w_2\) }}  = k_1(u_1 + w_1) + k_2(u_2 + w_2) = \underbrace{(k_1 u_1 + k_1 w_1)}_{\text{\(u_3 \in U\) per il 2° criterio}} + \underbrace{ (k_2 u_2 + k_2 w_2)}_{\text{\(w_3 \in W\) per il 2° criterio}}  
\] \[
    \implies u_3 + w_3 \in U + W \implies \text{ per il 2° criterio } \ U + W \le V
\]}

\mprop{}{Siano \(U, W \le V_n(K)\) allora \(U + W\) è il più piccolo sottospazio di \(V\) che cotiene \(U \cup W\); equivalentemente \[\mcL(U \cup W) = U + W\]}
\dfn{Somma diretta}{Dati \(U, W \le V_n(K)\) diremo che \(U + W\) è somma diretta se \(\forall v \in U + W\) può essere scritto come unico modo come \(u + w\). Equivalentemente \[
    \forall v \in U + W \quad \exists ! \ u \in U \ e \ w \in W : \quad v = u + w
\]Se \(U + W\) è una somma diretta allora la indicheremo con \(U \oplus W\). }

\mprop{}{Siano \(U, W \le V_n(K)\) allora \(U \oplus W \iff U \cap W = \{\ul{0} \} \).}
\pf{Dimostrazione}{\( \implies\) Siano \(U, W\) in somma diretta e sia, per assurdo: \(x \in U \cap W\) con \(x \neq \ul{0} \). Sia \(v = u + w\) con \(u \in U \ e \ w \in W\). Consideriamo \[
    v + x - x = v \implies v = u + w + x - x = \underbrace{u + x}_{\in U} + \underbrace{w - x}_{\in W} = u_1 + w_1
\] \[
    u = u + x \quad e \quad w = w - x \text{ poiché la somma è diretta } \implies x = \ul{0} \implies \text{\textbf{Assurdo!}} \implies U \cap W = \{\ul{0} \} 
\] \( \impliedby\) Siano \(U, W: \ U \cap W = \{\ul{0} \}\) e supponiamo per assurdo che esista \(v \in U + W:\) \[
    v = u_1 + w_1 \quad e \quad v = u_2 + w_2 \qquad \text{ con } \ u_1, u_2 \in U \quad e \quad w_1, w_2 \in W \quad e \quad (u_1, w_1) \neq (u_2, w_2)
\] \[
    u_1 + w_1 = u_2 + w_2 \quad v_2 = \underbrace{u_1 - u_2}_{\in U} = \underbrace{w_2 - w_1}_{\in W} \in U \cap W
\] \[
    \implies u_1 - u_2 = \ul{0} \quad e \quad w_2 - w_1 = \ul{0}
\] \[
    \implies u_1 = u_2 \quad e \quad w_1 = w_2
\] che è \textbf{assurdo!} Questo perché avevamo supposto che \(v\) avesse due scritture distinte come somma i elementi di \(U \ e \ W.\) \[
    \implies \exists ! \ (u_1, w_1): \quad u, \in U \quad e \quad w_1 \in W: \quad v=u_1 + w_1 \ e \ U \oplus W 
\]}

\cor{}{Siano \(U, W \le V_n(K)\) allora \(V = U \oplus W \iff U + W = V \ e \ U \cap W = \{\ul{0} \} \).}
\nt{Siano \(U, W \le V_n(K)\) e sia \(B_1\) una base di \(V\) e \(B_2\) una base di \(W\) \( \implies B_1 \cup B_2\) è sequenza di generatori per lo spazio \(U + W\). In generale l'unione di due basi, non è a sua volta una base per \(U + W.\) }

\mprop{}{Siano \(U, M \le V_n(K): U \oplus W\) e sia \(A\) una sequenza libera di vettori di \(U\) e \(B\) una sequenza libera di vettori di \(U\). Allora \(A \cup B\) è una sequenza libera di vettori della \(U \oplus W\).}
\pf{Dimostrazione}{Siano \(A = (u_1, u_2, ..., u_k)\) e \(B = (w_1, w_2, ..., w_h)\) e supponiamo per assurdo che \(a_1, a_2, ..., a_k \in K\) e \( b_1, b_2, ..., b_h \in K\), quindi per assurdo sia legata la combinazione lineare: \[
    \ul{0} = a_1 u_1 + a_2 u_2 + ... + a_k u_k + b_1 w_1 + b_2 w_2 + ... + b_h w_h \ \text{ non tutti nulli }
\] \[
    \underbrace{-(a_1 u_1 + a_2 u_2 + ... + a_k u_k)}_{ \in U } = \underbrace{b_1 w_1 + b_2 w_2 + ... + b_h w_h}_{\in W}
\] \[
    \implies \ul{0} = b_1 w_1 + b_2 w_2 + ... + b_h w_h \quad e \quad \ul{0} = a_1 u_1 + a_2 u_2 + ... + a_k w_k
\]ma \(A\) e \(B\) sono sequenze libere quindi \(a_1 = a_2 = ... = a_k = 0 \quad e \quad b_1 = b_2 = ... = b_h = 0\) 
\[ \implies \nexists a_1, a_2, ..., a_k, b_1, b_2, ..., b_h \text{ non tutti nulli: } \] 
\[
    \ul{0} = a_1 u_1 + a_2 u_2 + ... + a_k u_k + b_1 w_1 + b_2 w_2 + ... + b_h w_h \implies \text{\textbf{Assurdo!}}
\] \( \implies A \cup B\) è una sequenza libera. 
}

\cor{}{Siano \(U, W \in V_n(K): U \oplus W\) e siano \(B_U\) e \(B_W\) basi di \(U\) e \(W\) \( \implies B_U \cup B_W\) è una base per \(U \oplus W\). }

\mprop{Formula di Grassmann}{Dati \(U, W \le V_n(K)\) abbiamo che: \[
    \dim(U + W) + \dim(U \cap W) = \dim(U) + \dim(W)
\]}
\dfn{Complemento diretto}{Sia \(W \le V_n(K)\) si dice \textbf{complemento diretto} di \(W\) in \(V\) uno spazio \(U \le V: U \oplus W = V.\) }
\nt{Un complemento diretto di \(W\) in \(V\) esiste sempre e si trova estendendo una base di \(W\) a una base di \(V\). In generale questo non è unico.}

\chapter{Sistemi lineari}
\section{Determinante di una matrice quadrata}
\dfn{Determinante}{Sia \(A = (a _{ij})\) una matrice quadrata, di ordine \(n\), a elementi in un campo \(K.\) Si dice \textbf{determinante} di \(A\), e si scrive \(|A|\) oppure \(\det(A)\), l'elemento di \(K\) definito ricorsivamente come segue: \begin{enumerate}
    \item se \(n = 1 \qquad A = (a _{11}) \qquad \det(A) = |A| = a _{11}\) 
    \item se \(n > 1 \qquad A = a _{ij} \qquad \det(A)=(-1)^{1+1} a _{11} \det A _{11} + (-1)^{1+2} a _{12} \det A _{12} + ... + (-1)^{1 + n} a _{1n} \det A _{1n}\) 
\end{enumerate}}

Se \(A = \begin{pmatrix} a _{11} & a _{12} \\ a _{21} & a _{22} \end{pmatrix} \), il suo determinante è \(|A| = a _{11} a _{22} - a _{12} a _{21}\).

Mentre se \[A = 
\begin{pmatrix}
    a_{11} & a _{12} & a _{13} \\
    a _{21} & a _{22} & a _{23} \\
    a _{31} & a _{32} & a _{33} \\
\end{pmatrix}
\]
Allora la il determinante di \(A\) è \[
    |A| = a _{11} a _{22} a_{33} + a_{13} a_{21} a_{32} + a_{12} a_{23} a_{31} - a_{13} a_{22} a_{32} - a_{11} a_{23} a_{32} - a_{12} a_{21} a_{33}  
\]
\dfn{Complemento algebrico}{Sia \(A = (a_{ij} )\) una matrice quadrata di ordine \(n\), a elementi in campo \(K\). Si dice \textbf{complemento algebrico} dell'elemento \(a_{hk} \), e si indica \(\Gamma_{hk} \), il determinante della matrice quadrata di ordine \(n -1\), ottenuta da \(A\) sopprimendo la h-esima riga e la k-esima colonna, preso con il segno \((-1)^{h+k} \). }
\thm{Primo teorema di Laplace}{Data la matrice quadrata di ordine \(n\), la somma dei prodotti degli elementi di una sua riga (o colonna), per i rispettivi complementi algebrici, è il determinante di \(A.\) }
Pertanto, la formula per il calcolo del determinante di \(A = (a_{ij} )\) rispetto alla a i-esima riga è \[
    |A| = \sum_{j = 1}^{n} a_{ij} \Gamma _{ij} \qquad \forall i = 1,2,..., n
\] rispetto alla j-esima colonna è \[
    |A| = \sum_{i = 1}^{n} a_{ij} \Gamma _{ij} \qquad \forall j = 1,2,..., n
\]

\thm{Secondo teorema di Laplace}{Sia \(A\) una matrice quadrata di ordine \(n\). La somma dei prodotti degli elementi di una sua riga (o colonna) per i complementi algebrici degli elementi di un'altra riga (o colonna) vale zero. Quindi \[
    A \in M_n(K) \implies
\begin{cases}
    a_{i1} \Gamma_{j1} + a_{i2} \Gamma_{j2} + ... + a_{in} \Gamma_{jn} = 0 \quad i \neq j \\
    a_{1i} \Gamma_{1j} + a_{2i} \Gamma_{2j} + ... + a_{ni} \Gamma_{nj} = 0 \quad i \neq j \\
\end{cases}
\]}

\thm{Teorema di Binet}{Date due matrici quadrate di ordine \(n\), \(A\) e \(B\), il determinante della matrice prodotto \(A \cdot B\) è uguale al prodotto dei determinanti di \(A\) e \(B\), cioè \[
    |A \cdot B| = |A| |B| 
\] }

\section{Matrici invertibili}
\dfn{Matrice invertibile}{Una matrice quadrata, di ordine \(n\), si dice \textbf{invertibile} quando esiste una matrice \(B\), quadrata e dello stesso ordine, tale che \(A \cdot B = B \cdot A = I_n\), dove \(I_n\) è la matrice identica di ordine \(n\). La matrice \(B\) si dice \textbf{inversa} di \(A\) e si indica \(A^{-1} \).}

\thm{}{Sia \(A \in M_n(K)\); allora \(A\) è invertibile \( \iff |A| \neq 0\) e in tal caso \[
    A_{-1} = \frac{1}{|A| }\left.^tA_a\right.
\] dove \(A_a\) si chiama \textbf{matrice aggiunta} di \(A\) ed è la matrice ottenuta da \(A\) sostituendo ogni elemento con il suo complemento algebrico \(\Gamma\). }

\section{Dipendenza lineare e determinanti}
\dfn{Minore}{Sia \(A \in K^{m,n} \). Si chiama \textbf{minore di ordine \(p\)} estratto da \(A\), con \(p \in \mathbb{N}\), \(p \neq 0\), \(p \le \min \{m,n\} \), una matrice quadrata di ordine \(p\) ottenuta cancellando \(m-p\) righe e \(n-p\) colonna da \(A\). }

\dfn{Rango}{Si chiama \textbf{rango} di \(A \in K^{m,n} \) (e si indica con \(\rho(A)\) ) l'ordine massimo di un minore estraibile da \(A\) con \(\det \neq 0\).}

\nt{\begin{enumerate}
    \item \(\rho(A) = 0 \iff A = 0\)
    \item \(A \neq 0 \quad 1 \le \rho(A) \le \min \{m,n\} \)
    \item \(\rho(A) = p \) se e solo se: \begin{enumerate}
        \item esiste un minore di \(A\) di ordine \(p\) con \(\det \neq 0\);
        \item tutti i minori di ordine maggiori di \(p\) hanno determinante nullo.
    \end{enumerate}
\end{enumerate}}
\end{document}
